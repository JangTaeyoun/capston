# -*- coding: utf-8 -*-
import os
import random
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, Subset

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
from sklearn.preprocessing import StandardScaler


# ---------------------------------------------------------------------
# 0) í™˜ê²½ ì„¤ì • (ì¬í˜„ì„± & ì„±ëŠ¥)
# ---------------------------------------------------------------------
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

set_seed(42)
torch.set_float32_matmul_precision('high')
if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True


# -----------------------------
# 1. ë°ì´í„° ì¦ê°• (ì‘ì€ ë…¸ì´ì¦ˆ)
# -----------------------------
def augment_features(features, noise_std=0.01):
    noise = torch.randn_like(features) * noise_std
    return features + noise


# ---------------------------------------------
# 2. source_type ê¸°ë°˜ ì‹œê³„ì—´ ê·¸ë˜í”„ ë°ì´í„°ì…‹
#    - ë…¸ë“œ ì„ íƒì€ past ê¸°ì¤€
#    - ë¼ë²¨ì€ future_df ì¡°íšŒ, ì—†ìœ¼ë©´ 0
#    - ì—£ì§€ ìƒì„±: source_type ê·¸ë£¹ ë‚´ Top-K í˜ì–´ë§(í­ì¦ ë°©ì§€)
# ---------------------------------------------
class SourceBasedSocialMediaGraphDataset(Dataset):
    def __init__(self, past_df, future_df, time_windows=10,
                 max_nodes=None, random_sample=True, pair_topk=5):
        self.past_df = past_df.copy()
        self.future_df = future_df.copy()
        self.time_windows = time_windows
        self.pair_topk = max(1, int(pair_topk))

        if 'source_type' not in self.past_df.columns:
            raise ValueError("source_type ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        if 'video_id' not in self.past_df.columns:
            raise ValueError("video_id ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. past_dfë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # --- (A) ë…¸ë“œ ì„ íƒì€ past ê¸°ì¤€ ---
        unique_videos = self.past_df['video_id'].unique().tolist()

        # ë…¸ë“œ ì œí•œ
        if max_nodes and len(unique_videos) > max_nodes:
            if random_sample:
                selected_videos = np.random.choice(unique_videos, max_nodes, replace=False)
            else:
                top_videos = self.past_df.groupby('video_id', as_index=False)['views'].max() \
                                         .nlargest(max_nodes, 'views')['video_id'].tolist()
                selected_videos = top_videos
        else:
            selected_videos = unique_videos

        self.past_df = self.past_df[self.past_df['video_id'].isin(selected_videos)].reset_index(drop=True)
        # future_dfëŠ” ë¼ë²¨ ê³„ì‚°ì—ë§Œ ì“°ë¯€ë¡œ ì „ì²´ ìœ ì§€(ì—†ìœ¼ë©´ 0 ë¼ë²¨ë¡œ ì²˜ë¦¬)
        self.future_df = self.future_df.copy().reset_index(drop=True)

        self.video_to_node = {vid: idx for idx, vid in enumerate(sorted(set(self.past_df['video_id'])))}
        self.node_to_video = {idx: vid for vid, idx in self.video_to_node.items()}
        self.num_nodes = len(self.video_to_node)

        print(f"ì„ íƒëœ ë…¸ë“œ ìˆ˜: {self.num_nodes}")
        print(f"ëœë¤ ìƒ˜í”Œë§: {random_sample}")
        print("source_type ë¶„í¬:")
        print(self.past_df['source_type'].value_counts().head(10))

        self.st_list = sorted(self.past_df['source_type'].unique().tolist())
        self.st_to_idx = {st: i for i, st in enumerate(self.st_list)}
        self.num_st = len(self.st_list)

        self.create_meaningful_temporal_graph()

    def _safe_ratio(self, a, b):
        a = float(a); b = float(b)
        return (a - b) / (max(a, b) + 1.0)

    def _label_from_future(self, dst_row):
        # dst_row: pastì˜ ë‹¨ì¼ í–‰
        dst_vid = dst_row['video_id']
        future_data = self.future_df[self.future_df['video_id'] == dst_vid]
        if len(future_data) == 0:
            return 0

        past_views = float(dst_row['views'])
        future_views = float(future_data.iloc[0]['views'])
        view_increase = future_views - past_views

        # ë‚ ì§œ ê³„ì‚°(ê°€ëŠ¥í•œ ê²½ìš° ì›ë³¸ ë‚ ì§œ, ì•„ë‹ˆë©´ timestampâ†’date)
        if 'original_date' in dst_row and pd.notnull(dst_row['original_date']):
            try:
                first_date = pd.to_datetime(dst_row['original_date'])
            except Exception:
                first_date = pd.to_datetime('2025-05-10')
        else:
            if 'timestamp' in dst_row and pd.notnull(dst_row['timestamp']):
                try:
                    first_date = pd.to_datetime(dst_row['timestamp'])
                except Exception:
                    first_date = pd.to_datetime('2025-05-10')
            else:
                first_date = pd.to_datetime('2025-05-10')

        # (ê¸°ì¡´ ì •ì±… ìœ ì§€) êµ¬ê°„ë³„ ì„ê³„ê°’
        d = first_date
        if pd.to_datetime('2025-05-10') <= d < pd.to_datetime('2025-05-18'):
            return 1 if view_increase >= 100000 else 0
        elif pd.to_datetime('2025-05-18') <= d < pd.to_datetime('2025-05-25'):
            return 1 if view_increase >= 80000 else 0
        elif pd.to_datetime('2025-05-25') <= d < pd.to_datetime('2025-06-01'):
            return 1 if view_increase >= 60000 else 0
        elif pd.to_datetime('2025-06-01') <= d < pd.to_datetime('2025-06-08'):
            return 1 if view_increase >= 50000 else 0
        elif pd.to_datetime('2025-06-08') <= d < pd.to_datetime('2025-06-15'):
            return 1 if view_increase >= 40000 else 0
        elif pd.to_datetime('2025-06-15') <= d < pd.to_datetime('2025-06-22'):
            return 1 if view_increase >= 30000 else 0
        elif pd.to_datetime('2025-06-22') <= d < pd.to_datetime('2025-06-30'):
            return 1 if view_increase >= 20000 else 0
        else:
            return 0

    def create_meaningful_temporal_graph(self):
        print("source_type ê¸°ë°˜ ì˜ë¯¸ ìˆëŠ” ì‹œê³„ì—´ ê·¸ë˜í”„ ë°ì´í„° ìƒì„± ì¤‘...")
        timestamps = self.past_df['timestamp'].values if 'timestamp' in self.past_df.columns else np.arange(len(self.past_df))
        timestamps = np.nan_to_num(timestamps, nan=0.0)
        print(f"Timestamp ë²”ìœ„: {timestamps.min()} ~ {timestamps.max()}")
        time_bins = np.linspace(timestamps.min(), timestamps.max(), self.time_windows + 1)

        self.src_nodes, self.dst_nodes = [], []
        self.edge_features, self.timestamps, self.labels = [], [], []
        self.source_types = []

        # ì°½ë³„ ì²˜ë¦¬
        for i in range(self.time_windows):
            start_time, end_time = time_bins[i], time_bins[i + 1]
            mask = (timestamps >= start_time) & (timestamps < end_time)
            window_data = self.past_df[mask]
            if len(window_data) == 0:
                continue

            # source_type ê·¸ë£¹ë³„ Top-K í˜ì–´ë§
            for source_type, group in window_data.groupby('source_type'):
                if len(group) < 2:
                    continue

                # ì¡°íšŒìˆ˜ ê¸°ì¤€ ì •ë ¬
                g_sorted = group.sort_values('views', ascending=False).reset_index(drop=True)
                # ìƒìœ„ Kì™€ í•˜ìœ„ K ì„ íƒ(ê²¹ì¹˜ë©´ uniq)
                top_idx = list(range(min(self.pair_topk, len(g_sorted))))
                bot_idx = list(range(max(0, len(g_sorted) - self.pair_topk), len(g_sorted)))
                cand_idx = sorted(set(top_idx + bot_idx))
                if len(cand_idx) < 2:
                    continue

                vids = g_sorted.loc[cand_idx, 'video_id'].tolist()
                sub = g_sorted.loc[cand_idx].reset_index(drop=True)

                # ì–‘ë°©í–¥ ë¶€ë¶„-ì „ìŒ(í­ë°œ ë°©ì§€ìš© ì†Œìˆ˜ë§Œ)
                for j in range(len(sub)):
                    for k in range(len(sub)):
                        if j == k:
                            continue
                        src_vid = sub.iloc[j]['video_id']
                        dst_vid = sub.iloc[k]['video_id']
                        if src_vid not in self.video_to_node or dst_vid not in self.video_to_node:
                            continue

                        src_node = self.video_to_node[src_vid]
                        dst_node = self.video_to_node[dst_vid]

                        src_data = sub.iloc[j]
                        dst_data = sub.iloc[k]

                        views_diff    = self._safe_ratio(src_data['views'],    dst_data['views'])
                        likes_diff    = self._safe_ratio(src_data['likes'],    dst_data['likes'])
                        comments_diff = self._safe_ratio(src_data['comments'], dst_data['comments'])

                        t_norm = i / max(self.time_windows - 1, 1)

                        # âœ… ì¶”ê°€: ì†ŒìŠ¤íƒ€ì… one-hot
                        st_idx = self.st_to_idx[source_type]                 # 1-1ì—ì„œ ë§Œë“  ë§¤í•‘ ì‚¬ìš©
                        st_onehot = np.zeros(self.num_st, dtype=np.float32)
                        st_onehot[st_idx] = 1.0

                        # âœ… edge feature í™•ì¥: [diff 3] + [time 1] + [source_type one-hot]
                        edge_feat = [views_diff, likes_diff, comments_diff, t_norm] + st_onehot.tolist()

                        self.src_nodes.append(src_node)
                        self.dst_nodes.append(dst_node)
                        self.edge_features.append(edge_feat)
                        self.timestamps.append(float(i))
                        self.source_types.append(source_type)

                        viral_label = self._label_from_future(dst_data)
                        self.labels.append(viral_label)

        self.src_nodes = np.array(self.src_nodes, dtype=np.int64)
        self.dst_nodes = np.array(self.dst_nodes, dtype=np.int64)
        self.edge_features = np.array(self.edge_features, dtype=np.float32)
        self.timestamps = np.array(self.timestamps, dtype=np.float32)
        self.labels = np.array(self.labels, dtype=np.int64)

        print(f"ìƒì„±ëœ ê·¸ë˜í”„: {len(self.src_nodes)}ê°œ ì—£ì§€, {self.num_nodes}ê°œ ë…¸ë“œ")
        print(f"ë°”ì´ëŸ´ ë¼ë²¨ ë¶„í¬: {np.sum(self.labels)}/{len(self.labels)} ({np.mean(self.labels)*100:.1f}%)")
        source_type_counts = pd.Series(self.source_types).value_counts()
        print("\nsource_typeë³„ ì—£ì§€ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        print(source_type_counts.head(10))
        if len(self.src_nodes) == 0:
            raise ValueError("ì—£ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    def __len__(self):
        return len(self.src_nodes)

    def __getitem__(self, idx):
        return (
            self.src_nodes[idx],
            self.dst_nodes[idx],
            self.edge_features[idx],
            self.timestamps[idx],
            self.labels[idx]
        )


# ---------------------------------
# 2-1. ê³µì¶œí˜„ ê¸°ë°˜ í¬ì†Œ ì¸ì ‘í–‰ë ¬ ìƒì„± (SCNìš©)
#      - Train ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©í•´ ëˆ„ìˆ˜ ì°¨ë‹¨
# ---------------------------------
def build_cooccurrence_adj_from_indices(dataset, indices, num_nodes, symmetric=True, add_self_loops=True):
    from collections import defaultdict
    counts = defaultdict(int)

    src_arr = dataset.src_nodes[indices]
    dst_arr = dataset.dst_nodes[indices]

    for s, d in zip(src_arr, dst_arr):
        s = int(s); d = int(d)
        counts[(s, d)] += 1
        if symmetric:
            counts[(d, s)] += 1

    if len(counts) == 0:
        # fall back to identity
        indices_t = torch.arange(num_nodes)
        i = torch.stack([indices_t, indices_t])
        v = torch.ones(num_nodes, dtype=torch.float32)
        return torch.sparse_coo_tensor(i, v, (num_nodes, num_nodes)).coalesce()

    rows, cols, vals = [], [], []
    for (r, c), v in counts.items():
        rows.append(r); cols.append(c); vals.append(float(v))

    i = torch.tensor([rows, cols], dtype=torch.long)
    v = torch.tensor(vals, dtype=torch.float32)
    adj = torch.sparse_coo_tensor(i, v, (num_nodes, num_nodes)).coalesce()

    # Row-normalize
    row_sums = torch.sparse.sum(adj, dim=1).to_dense().clamp_min(1e-6)
    norm_v = adj.values() / row_sums[adj.indices()[0]]
    adj = torch.sparse_coo_tensor(adj.indices(), norm_v, (num_nodes, num_nodes)).coalesce()

    # Add self-loops and renormalize
    if add_self_loops:
        diag_idx = torch.arange(num_nodes, dtype=torch.long)
        diag_i = torch.stack([diag_idx, diag_idx])
        diag_v = torch.ones(num_nodes, dtype=torch.float32)
        eye = torch.sparse_coo_tensor(diag_i, diag_v, (num_nodes, num_nodes)).coalesce()

        adj = (adj + eye).coalesce()
        row_sums = torch.sparse.sum(adj, dim=1).to_dense().clamp_min(1e-6)
        v2 = adj.values() / row_sums[adj.indices()[0]]
        adj = torch.sparse_coo_tensor(adj.indices(), v2, (num_nodes, num_nodes)).coalesce()

    return adj


# -----------------------------
# 3. TGN Memory ëª¨ë“ˆ
# -----------------------------
class SourceBasedTGNMemory(nn.Module):
    def __init__(self, num_nodes, memory_dim, message_dim, edge_feat_dim=3, time_decay_alpha=0.1):
        super().__init__()
        self.memory = nn.Parameter(torch.randn(num_nodes, memory_dim) * 0.1, requires_grad=False)
        self.register_buffer('last_update', torch.zeros(num_nodes))
        self.gru = nn.GRUCell(message_dim, memory_dim)
        self.message_encoder = nn.Sequential(
            nn.Linear(memory_dim * 2 + edge_feat_dim, message_dim),
            nn.ReLU(),
            nn.Linear(message_dim, message_dim)
        )
        self.time_decay_alpha = time_decay_alpha

    def forward(self, src_nodes, dst_nodes, edge_feat, timestamps):
        device = self.memory.device
        src_nodes = src_nodes.long().to(device)
        dst_nodes = dst_nodes.long().to(device)
        edge_feat = edge_feat.to(device)
        timestamps = timestamps.to(device)

        batch_size = len(src_nodes)
        for i in range(batch_size):
            s = src_nodes[i].item()
            d = dst_nodes[i].item()
            t = timestamps[i].item()

            # êµì²´ í›„
            dt_s_t = torch.tensor(max(t - self.last_update[s].item(), 0.0),
                      device=self.memory.device, dtype=self.memory.dtype)
            dt_d_t = torch.tensor(max(t - self.last_update[d].item(), 0.0),
                      device=self.memory.device, dtype=self.memory.dtype)

            decay_s = torch.exp(-self.time_decay_alpha * dt_s_t)
            decay_d = torch.exp(-self.time_decay_alpha * dt_d_t)

            prev_src = (self.memory[s] * decay_s).unsqueeze(0)
            prev_dst = (self.memory[d] * decay_d).unsqueeze(0)


            msg_in = torch.cat([prev_src, prev_dst, edge_feat[i].unsqueeze(0)], dim=1)
            message = self.message_encoder(msg_in)

            upd_src = self.gru(message, prev_src)
            upd_dst = self.gru(message, prev_dst)

            # êµì²´ í›„
            with torch.no_grad():
                self.memory[s].copy_(upd_src.squeeze(0))
                self.memory[d].copy_(upd_dst.squeeze(0))
                 # last_updateë„ dtype/device ë§ì¶° ì•ˆì „í•˜ê²Œ ê¸°ë¡
                t_val = torch.as_tensor(t, device=self.last_update.device, dtype=self.last_update.dtype)
                self.last_update[s].copy_(t_val)
                self.last_update[d].copy_(t_val)


    def get_memory(self, node_indices):
        return self.memory[node_indices]

    def reset_memory(self):
        with torch.no_grad():
            self.memory.copy_(torch.randn_like(self.memory) * 0.1)
            self.last_update.zero_()



# --------------------------------
# 4. Graph Transformer Layer
# --------------------------------
class SourceBasedGraphTransformerLayer(nn.Module):
    def __init__(self, dim, heads=4, ffn_dim=64, dropout=0.3):
        super().__init__()
        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True, dropout=dropout)
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        self.ffn = nn.Sequential(
            nn.Linear(dim, ffn_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(ffn_dim, dim),
            nn.Dropout(dropout)
        )

    def forward(self, x, mask=None):
        attn_out, _ = self.attn(x, x, x, attn_mask=mask)
        x = self.norm1(x + attn_out)
        ffn_out = self.ffn(x)
        return self.norm2(x + ffn_out)


# -----------------------------
# 5. SCN Layer (í¬ì†Œ/ë°€ì§‘ adj ì§€ì›)
# -----------------------------
class SourceBasedSCNLayer(nn.Module):
    def __init__(self, in_dim, out_dim, dropout=0.3):
        super().__init__()
        self.linear = nn.Linear(in_dim, out_dim)
        self.dropout = nn.Dropout(dropout)
        self.norm = nn.LayerNorm(out_dim)

    def forward(self, x, adj):
        if x.dim() != 2:
            x = x.view(x.size(0), -1)

        if hasattr(adj, "is_sparse") and adj.is_sparse:
            if adj.dtype != torch.float32:
                adj = adj.float()
            adj = adj.coalesce()
            orig_dtype = x.dtype
            if x.is_cuda:
                with torch.cuda.amp.autocast(False):
                    support = torch.sparse.mm(adj, x.float())
            else:
                support = torch.sparse.mm(adj, x.to(torch.float32))
            support = support.to(orig_dtype)
        else:
            if adj.shape[0] == adj.shape[1] and torch.allclose(
                adj, torch.eye(adj.shape[0], device=adj.device, dtype=adj.dtype)
            ):
                support = x
            else:
                support = torch.mm(adj, x)

        out = self.linear(support)
        out = self.norm(out)
        return self.dropout(F.relu(out))


# ------------------------------------------------
# 6. ì „ì²´ ëª¨ë¸
# ------------------------------------------------
class SourceBasedGT_TGN_SocialViral(nn.Module):
    def __init__(self, num_nodes, node_feat_dim, memory_dim=24, message_dim=32, scn_dim=12, num_gt_layers=1,
                 update_memory_in_eval=True, edge_feat_dim=3, heads=2):
        super().__init__()
        self.num_nodes = num_nodes
        self.memory = SourceBasedTGNMemory(num_nodes, memory_dim, message_dim, edge_feat_dim=edge_feat_dim, time_decay_alpha=0.1)
        self.node_emb = nn.Linear(node_feat_dim, memory_dim)
        self.mem_proj = nn.Linear(memory_dim * 2, memory_dim)

        self.gt_layers = nn.ModuleList([
            SourceBasedGraphTransformerLayer(memory_dim, heads=4, ffn_dim=64, dropout=0.3)
            for _ in range(num_gt_layers)
        ])
        self.scn = SourceBasedSCNLayer(memory_dim, scn_dim, dropout=0.3)

        self.edge_pred = nn.Sequential(
            nn.Linear(2 * scn_dim, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(16, 1)
        )

        self.update_memory_in_eval = update_memory_in_eval

        self.register_buffer("all_nodes_buf", torch.arange(num_nodes))

    def forward(self, src, dst, edge_feat, timestamps, node_features, adj):
        device = node_features.device
        batch_size = len(src)

        # === ì˜ˆì¸¡ìš© ìŠ¤ëƒ…ìƒ·ì„ ë¨¼ì € í™•ë³´ ===
        node_embs = self.node_emb(node_features)                     # (N, M)
        all_nodes = self.all_nodes_buf.to(device)
        mem_snapshot = self.memory.get_memory(all_nodes).clone()     # ìŠ¤ëƒ…ìƒ· ê³ ì •

        x0 = torch.cat([node_embs, mem_snapshot], dim=-1)            # (N, 2M)
        x0 = self.mem_proj(x0)                                       # (N, M)

        gt_input = x0.unsqueeze(0).expand(batch_size, -1, -1)        # (B, N, M)
        gt_out = gt_input
        for gt_layer in self.gt_layers:
            gt_out = gt_layer(gt_out)

        # ë°°ì¹˜ ì°¨ì› ë°˜ë³µ (ê°„ë‹¨ ëª…ë£Œ ìœ ì§€)
        scn_out = torch.stack([self.scn(gt_out[i], adj) for i in range(gt_out.size(0))], dim=0)  # (B, N, scn_dim)

        b_idx = torch.arange(src.size(0), device=device)
        src_emb = scn_out[b_idx, src]
        dst_emb = scn_out[b_idx, dst]
        logits = self.edge_pred(torch.cat([src_emb, dst_emb], dim=-1)).squeeze(-1)

        # === ì˜ˆì¸¡ì„ ë§Œë“  ë’¤ì—ì•¼ ë©”ëª¨ë¦¬ë¥¼ ì—…ë°ì´íŠ¸ ===
        if self.training or self.update_memory_in_eval:
            self.memory(src, dst, edge_feat, timestamps)

        return logits


    def reset_memory(self):
        self.memory.reset_memory()


# ---------------------------------
# 7. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
# ---------------------------------
def source_based_load_and_prepare_data(past_file, future_file):
    print("source_type ê¸°ë°˜ ë°ì´í„° ë¡œë”© ì¤‘...")
    past_df = pd.read_csv(past_file, encoding='utf-8-sig')
    future_df = pd.read_csv(future_file, encoding='utf-8-sig')

    past_df.columns = [col.strip() for col in past_df.columns]
    future_df.columns = [col.strip() for col in future_df.columns]

    if 'source_type' not in past_df.columns:
        raise ValueError("past_dfì— source_type ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    if 'video_id' not in past_df.columns:
        raise ValueError("past_dfì— video_id ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    for col in ['views', 'likes', 'comments']:
        if col in past_df.columns:
            past_df[col] = pd.to_numeric(past_df[col], errors='coerce').fillna(0)
        if col in future_df.columns:
            future_df[col] = pd.to_numeric(future_df[col], errors='coerce').fillna(0)

    if 'timestamp' not in past_df.columns:
        past_df['timestamp'] = np.arange(len(past_df))
        past_df['original_date'] = pd.to_datetime('2025-05-10') + pd.to_timedelta(past_df['timestamp'], unit='D')
    else:
        past_df['original_date'] = pd.to_datetime(past_df['timestamp'], errors='coerce')
        past_df['timestamp'] = (past_df['original_date'] - past_df['original_date'].min()).dt.days
        if isinstance(past_df['timestamp'], pd.Series):
            past_df['timestamp'] = past_df['timestamp'].fillna(0)

    print(f"ê³¼ê±° ë°ì´í„°: {len(past_df)}ê°œ ì˜ìƒ")
    print(f"ë¯¸ë˜ ë°ì´í„°: {len(future_df)}ê°œ ì˜ìƒ")
    print(f"source_type ì¢…ë¥˜: {past_df['source_type'].nunique()}ê°œ")
    return past_df, future_df


# ------------------------------------------------------------
# 8. ì‹œê°„ìˆœ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ëˆ„ìˆ˜ ë°©ì§€, BF16, NaN ê°€ë“œ)
# ------------------------------------------------------------
def source_based_train_gt_tgn_social(dataset, node_features, num_nodes,
                                     device='cpu', epochs=100, train_batch_size=32, val_batch_size=16, lr=0.001):
    print("Source-based GT-TGN+SCN ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

    # ì‹œê°„ìˆœ split (80% / 20%)
    order = np.argsort(dataset.timestamps)
    total_len = len(dataset)
    train_size = int(0.8 * total_len)
    train_indices = order[:train_size]
    val_indices   = order[train_size:]

    train_dataset = Subset(dataset, train_indices)
    val_dataset   = Subset(dataset, val_indices)

    pin = (device == 'cuda')
    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False, pin_memory=True, num_workers=2)
    val_loader   = DataLoader(val_dataset,   batch_size=val_batch_size,   shuffle=False, pin_memory=True, num_workers=2)

    # === (ëˆ„ìˆ˜ ì°¨ë‹¨) Train ì—£ì§€ë§Œìœ¼ë¡œ adj ìƒì„± ===
    adj = build_cooccurrence_adj_from_indices(dataset, train_indices, num_nodes, symmetric=True, add_self_loops=True)

    # ğŸ”¹ ì¶”ê°€: edge feature ì°¨ì› íŒŒì•…
    edge_feat_dim = dataset.edge_features.shape[1]  # 3 + 1(time) + num_st (ë˜ëŠ” í‘œì¤€í™” í›„ ë™ì¼)

    # ëª¨ë¸
    model = SourceBasedGT_TGN_SocialViral(
        num_nodes=num_nodes,
        node_feat_dim=node_features.shape[1],
        memory_dim=24,
        message_dim=32,
        scn_dim=12,
        num_gt_layers=1,
        update_memory_in_eval=True,  # âœ… ê²€ì¦/í‰ê°€ì—ì„œë„ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        edge_feat_dim=edge_feat_dim,
        heads=2).to(device)

    # === (ëˆ„ìˆ˜ ì°¨ë‹¨) pos_weightë„ Train ë¼ë²¨ë¡œë§Œ ê³„ì‚° ===
    train_labels_for_weight = dataset.labels[train_indices]
    num_pos = float(train_labels_for_weight.sum())
    num_neg = float(len(train_labels_for_weight) - num_pos)

    # ratio ê³„ì‚° + ê·¹ë‹¨ê°’ ë°©ì§€ í´ë¨í”„
    ratio = num_neg / max(num_pos, 1.0)   # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
    ratio = max(1.0, min(ratio, 20.0))
    pos_weight = torch.tensor([ratio], device=device)              # ìƒí•œê°’ 20 (í•„ìš”ì— ë”°ë¼ 10~50 ì¡°ì ˆ ê°€ëŠ¥)

    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    print(f"[info] pos_weight(ratio) = {ratio:.3f}")

    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.7)

    best_val_auc = 0.0
    train_losses, val_metrics = [], []

    for epoch in range(epochs):
        # ---------------- Train ----------------
        model.train()
        model.reset_memory()
        total_loss = 0.0

        node_features_dev = node_features.to(device)
        adj_dev = adj.to(device)

        for src, dst, edge_feat, ts, labels in train_loader:
            src, dst = src.to(device), dst.to(device)
            edge_feat = torch.as_tensor(edge_feat, dtype=torch.float32, device=device)
            ts = torch.as_tensor(ts, dtype=torch.float32, device=device)
            labels = torch.as_tensor(labels, dtype=torch.float32, device=device)

            node_features_aug = augment_features(node_features_dev)

            optimizer.zero_grad(set_to_none=True)
            with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=(device == 'cuda')):
                pred = model(src, dst, edge_feat, ts, node_features_aug, adj_dev)
                pred = torch.nan_to_num(pred, nan=0.0, posinf=50.0, neginf=-50.0)
                
                bce_loss = criterion(pred, labels)

                 # 2) ìŒëŒ€ ìˆœìœ„ ì†ì‹¤ (AUC ì§ì ‘ ë°€ì–´ì¤Œ)
                pos_idx = (labels > 0.5).nonzero(as_tuple=False).squeeze(-1)
                neg_idx = (labels < 0.5).nonzero(as_tuple=False).squeeze(-1)
                pair_loss = torch.tensor(0.0, device=pred.device)
                if pos_idx.numel() > 0 and neg_idx.numel() > 0:
                    k = min(256, pos_idx.numel(), neg_idx.numel())  # ê³¼ë„í•œ ê³„ì‚° ë°©ì§€ìš© ìƒ˜í”Œë§
                    p = pos_idx[torch.randint(pos_idx.numel(), (k,), device=pred.device)]
                    n = neg_idx[torch.randint(neg_idx.numel(), (k,), device=pred.device)]
                    s_pos = pred[p]
                    s_neg = pred[n]
                    pair_loss = F.softplus(-(s_pos - s_neg)).mean()  # log(1+exp(-(pos-neg)))

                # 3) ìµœì¢… ì†ì‹¤
                loss = bce_loss + 0.2 * pair_loss  # ëŒë‹¤ 0.1~0.3ì—ì„œ ì¡°ì •

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            total_loss += loss.item()

        # ---------------- Validation ----------------
        model.eval()
        model.reset_memory()  # ì´ˆê¸°í™” í›„, evalì—ì„œë„ forwardê°€ ë©”ëª¨ë¦¬ë¥¼ ìˆœì°¨ ì—…ë°ì´íŠ¸í•¨

        node_features_eval = node_features.to(device)
        adj_eval = adj.to(device)

        # ğŸ”¹ ë©”ëª¨ë¦¬ ì›Œë°ì—…: Train ì—£ì§€ë¥¼ í•œ ë²ˆ í˜ë ¤ ë©”ëª¨ë¦¬ë§Œ ê°±ì‹  (ì˜ˆì¸¡ X)
        with torch.no_grad():
            for src_w, dst_w, edge_feat_w, ts_w, _ in train_loader:
                src_w, dst_w = src_w.to(device), dst_w.to(device)
                edge_feat_w = torch.as_tensor(edge_feat_w, dtype=torch.float32, device=device)
                ts_w = torch.as_tensor(ts_w, dtype=torch.float32, device=device)
                model.memory(src_w, dst_w, edge_feat_w, ts_w)

        val_preds, val_labels = [], []

        node_features_eval = node_features.to(device)
        adj_eval = adj.to(device)

        with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=(device == 'cuda')):
            for src, dst, edge_feat, ts, labels in val_loader:
                src, dst = src.to(device), dst.to(device)
                edge_feat = torch.as_tensor(edge_feat, dtype=torch.float32, device=device)
                ts = torch.as_tensor(ts, dtype=torch.float32, device=device)
                labels = labels.to(device)

                pred = model(src, dst, edge_feat, ts, node_features_eval, adj_eval)
                pred = torch.nan_to_num(pred, nan=0.0, posinf=50.0, neginf=-50.0)
                val_preds.append(torch.sigmoid(pred).float().cpu().numpy())
                val_labels.append(labels.cpu().numpy())

        val_preds = np.concatenate(val_preds) if len(val_preds) > 0 else np.array([])
        val_labels = np.concatenate(val_labels) if len(val_labels) > 0 else np.array([])
        val_preds = np.nan_to_num(val_preds, nan=0.5, posinf=1.0, neginf=0.0)

        if val_labels.size > 0:
            val_preds_binary = (val_preds > 0.5).astype(int)
            print(f"[ì§„ë‹¨] Val label ë¶„í¬: {np.bincount(val_labels.astype(int))}")
            print(f"[ì§„ë‹¨] Val ì˜ˆì¸¡ ë¶„í¬: {np.bincount(val_preds_binary)}")
            print(f"[ì§„ë‹¨] Val ì˜ˆì¸¡ í™•ë¥  í‰ê· : {np.mean(val_preds):.4f}")

            try:
                val_auc = roc_auc_score(val_labels, val_preds) if np.unique(val_labels).size > 1 else 0.5
            except Exception:
                val_auc = 0.5
            val_accuracy = accuracy_score(val_labels, val_preds_binary)
            val_precision = precision_score(val_labels, val_preds_binary, zero_division=0)
            val_recall = recall_score(val_labels, val_preds_binary, zero_division=0)
            val_f1 = f1_score(val_labels, val_preds_binary, zero_division=0)

            train_losses.append(total_loss / max(len(train_loader), 1))
            val_metrics.append({'auc': val_auc, 'accuracy': val_accuracy, 'precision': val_precision,
                                'recall': val_recall, 'f1': val_f1})

            scheduler.step(val_auc)

            if val_auc > best_val_auc:
                best_val_auc = val_auc
                torch.save(model.state_dict(), 'best_source_gt_tgn_social_re_000.pth')

            print(f"Epoch {epoch+1}/{epochs} | Train Loss: {train_losses[-1]:.4f} | "
                  f"Val AUC: {val_auc:.4f} | Val Acc: {val_accuracy:.4f} | "
                  f"Val Prec: {val_precision:.4f} | Val Recall: {val_recall:.4f} | "
                  f"Val F1: {val_f1:.4f}")
        else:
            print(f"Epoch {epoch+1}/{epochs} | Train Loss: {total_loss / max(len(train_loader), 1):.4f} | (ê²€ì¦ ìƒ˜í”Œ ì—†ìŒ)")

        if device == 'cuda':
            torch.cuda.empty_cache()

    print(f"ìµœê³  ê²€ì¦ AUC: {best_val_auc:.4f}")
    return model, train_losses, val_metrics, val_dataset, train_indices, val_indices, adj


# -------------------------------------------------
# 9. í‰ê°€ (val ì „ìš©, ë©”ëª¨ë¦¬ ê³ ì • ì´ˆê¸°í™” í›„ evalì—ì„œ ì—…ë°ì´íŠ¸)
# -------------------------------------------------
def source_based_evaluate_and_save_results(model, dataset_subset, node_features, adj, past_df, future_df,
                                           device='cpu', val_batch_size=16, out_csv='source_gt_tgn_social_viral_results(re_4000).csv',  warmup_indices=None):
    print("Source-based ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€ ì¤‘ (Validation subset)...")
    model.eval()
    model.reset_memory()

    pin = (device == 'cuda')

    # í•œ ë²ˆë§Œ ë””ë°”ì´ìŠ¤ë¡œ ì˜¬ë ¤ë‘ê¸°
    node_features_dev = node_features.to(device)
    adj_dev = adj.to(device)

    # âœ… Train ì—£ì§€ë¡œë§Œ ì›Œë°ì—… (ê²€ì¦ ì—£ì§€ ì ˆëŒ€ X)
    if warmup_indices is not None and len(warmup_indices) > 0:
        warm_ds = Subset(dataset_subset.dataset, warmup_indices)
        warm_loader = DataLoader(warm_ds, batch_size=val_batch_size, shuffle=False,
                             pin_memory=pin, num_workers=0)
    with torch.no_grad():
        for src_w, dst_w, edge_feat_w, ts_w, _ in warm_loader:
            src_w, dst_w = src_w.to(device), dst_w.to(device)
            edge_feat_w = torch.as_tensor(edge_feat_w, dtype=torch.float32, device=device)
            ts_w = torch.as_tensor(ts_w, dtype=torch.float32, device=device)
            model.memory(src_w, dst_w, edge_feat_w, ts_w)  # ì˜ˆì¸¡ X, ë©”ëª¨ë¦¬ë§Œ ì—…ë°ì´íŠ¸

    loader = DataLoader(dataset_subset, batch_size=val_batch_size, shuffle=False, pin_memory=pin, num_workers=0)

    all_preds, all_labels, all_src, all_dst = [], [], [], []

    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=(device == 'cuda')):
        for src, dst, edge_feat, ts, labels in loader:
            src, dst = src.to(device), dst.to(device)
            edge_feat = torch.as_tensor(edge_feat, dtype=torch.float32, device=device)
            ts = torch.as_tensor(ts, dtype=torch.float32, device=device)

            pred = model(src, dst, edge_feat, ts, node_features_dev, adj_dev)
            pred = torch.nan_to_num(pred, nan=0.0, posinf=50.0, neginf=-50.0)

            all_preds.append(torch.sigmoid(pred).float().cpu().numpy())
            all_labels.append(labels.cpu().numpy())
            all_src.append(src.cpu().numpy())
            all_dst.append(dst.cpu().numpy())

    if device == 'cuda':
        torch.cuda.empty_cache()

    all_preds = np.concatenate(all_preds) if len(all_preds) > 0 else np.array([])
    all_labels = np.concatenate(all_labels) if len(all_labels) > 0 else np.array([])
    all_src = np.concatenate(all_src) if len(all_src) > 0 else np.array([])
    all_dst = np.concatenate(all_dst) if len(all_dst) > 0 else np.array([])
    all_preds = np.nan_to_num(all_preds, nan=0.5, posinf=1.0, neginf=0.0)

    if all_labels.size > 0:
        y_pred_bin = (all_preds > 0.5).astype(int)
        accuracy = accuracy_score(all_labels, y_pred_bin)
        precision = precision_score(all_labels, y_pred_bin, zero_division=0)
        recall = recall_score(all_labels, y_pred_bin, zero_division=0)
        f1 = f1_score(all_labels, y_pred_bin, zero_division=0)
        auc = roc_auc_score(all_labels, all_preds) if np.unique(all_labels).size > 1 else None

        print("\n=== Source-based GT-TGN+SCN ëª¨ë¸ ì„±ëŠ¥ (Validation) ===")
        print(f"ì •í™•ë„: {accuracy:.4f}")
        print(f"ì •ë°€ë„: {precision:.4f}")
        print(f"ì¬í˜„ìœ¨: {recall:.4f}")
        print(f"F1-score: {f1:.4f}")
        print("AUC: NA (single class)" if auc is None else f"AUC: {auc:.4f}")
        print("\n=== ìƒì„¸ ë¶„ë¥˜ ë³´ê³ ì„œ ===")
        print(classification_report(all_labels, y_pred_bin))
    else:
        print("í‰ê°€ìš© ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")

    # ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame({
        'src_node_id': all_src.astype(int) if all_src.size > 0 else [],
        'dst_node_id': all_dst.astype(int) if all_dst.size > 0 else [],
        'src_video_id': [dataset_subset.dataset.node_to_video[int(s)] for s in all_src] if all_src.size > 0 else [],
        'dst_video_id': [dataset_subset.dataset.node_to_video[int(d)] for d in all_dst] if all_dst.size > 0 else [],
        'prediction_probability': all_preds,
        'actual_viral': all_labels,
        'predicted_viral': (all_preds > 0.5).astype(int)
    })

    if not results_df.empty:
        src_source_types, dst_source_types = [], []
        for src_vid, dst_vid in zip(results_df['src_video_id'], results_df['dst_video_id']):
            src_row = past_df[past_df['video_id'] == src_vid]
            dst_row = past_df[past_df['video_id'] == dst_vid]
            src_source_types.append(src_row['source_type'].iloc[0] if len(src_row) > 0 else 'Unknown')
            dst_source_types.append(dst_row['source_type'].iloc[0] if len(dst_row) > 0 else 'Unknown')

        results_df['src_source_type'] = src_source_types
        results_df['dst_source_type'] = dst_source_types
        results_df.to_csv(out_csv, index=False, encoding='utf-8-sig')
        print(f"\nê²°ê³¼ê°€ '{out_csv}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # source_typeë³„ ì„±ëŠ¥ (AUC ë‹¨ì¼í´ë˜ìŠ¤ ê°€ë“œ)
        print("\n=== Source-typeë³„ ì„±ëŠ¥ ë¶„ì„ (Validation) ===")
        for st in results_df['src_source_type'].unique():
            if st == 'Unknown':
                continue
            mask = (results_df['src_source_type'] == st)
            if mask.sum() <= 10:
                continue
            subset = results_df[mask]
            acc = accuracy_score(subset['actual_viral'], subset['predicted_viral'])
            pos_rate = float(subset['actual_viral'].mean())
            if subset['actual_viral'].nunique() < 2:
                print(f"{st}: AUC=NA (single class), Acc={acc:.4f}, PosRate={pos_rate:.1%} (n={len(subset)})")
            else:
                subset_auc = roc_auc_score(subset['actual_viral'], subset['prediction_probability'])
                print(f"{st}: AUC={subset_auc:.4f}, Acc={acc:.4f} (n={len(subset)})")

    return results_df


# -----------------------------
# 10. main
# -----------------------------
def main():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    try:
        # 1) ë°ì´í„° ë¡œë”©
        past_df, future_df = source_based_load_and_prepare_data(
            'filter(5.10~6.30).csv',
            'filter(7.3).csv'
        )

        # 2) ë…¸ë“œ ì œí•œ: 4000ê°œ (past ê¸°ì¤€), ì‹œê°„ì°½/í•™ìŠµ ì„¤ì •
        max_nodes = 4000
        time_windows = 5
        epochs = 100
        train_batch_size = 8
        val_batch_size = 4
        lr = 2.5e-4
        pair_topk = 40  # ê·¸ë£¹ ë‚´ ìƒÂ·í•˜ìœ„ Kë§Œ í˜ì–´ë§

        print(f"ì‹œê°„ ìœˆë„ìš°: {time_windows} | ì—í­: {epochs}")
        print(f"ë°°ì¹˜(Train/Val): {train_batch_size} / {val_batch_size} | lr: {lr}")

        # 3) ë°ì´í„°ì…‹ ìƒì„± (ë…¸ë“œ ì„ íƒì€ past ê¸°ì¤€, futureëŠ” ë¼ë²¨ë§Œ)
        print("source_type ê¸°ë°˜ ì‹œê³„ì—´ ê·¸ë˜í”„ ë°ì´í„° ìƒì„± ì¤‘...")
        dataset = SourceBasedSocialMediaGraphDataset(
            past_df=past_df,
            future_df=future_df,
            time_windows=time_windows,
            max_nodes=max_nodes,
            random_sample=True,
            pair_topk=pair_topk
        )

        # 4) ë…¸ë“œ íŠ¹ì„± (views/likes/comments â†’ í‘œì¤€í™” â†’ 10ì°¨ì› íŒ¨ë”©)
        node_feature_cols = ['views', 'likes', 'comments']
        node_features = []
        for idx in range(dataset.num_nodes):
            vid = dataset.node_to_video[idx]
            row = past_df[past_df['video_id'] == vid]
            if len(row) > 0:
                vals = [row.iloc[0][c] if c in row.columns and pd.notnull(row.iloc[0][c]) else 0 for c in node_feature_cols]
                node_features.append(vals)
            else:
                node_features.append([0] * len(node_feature_cols))
        node_features = np.array(node_features, dtype=np.float32)
        scaler = StandardScaler()
        node_features = scaler.fit_transform(node_features)
        node_features = torch.tensor(node_features, dtype=torch.float32)
        if node_features.shape[1] < 10:
            pad = torch.zeros((node_features.shape[0], 10 - node_features.shape[1]), dtype=torch.float32)
            node_features = torch.cat([node_features, pad], dim=1)

        print(f"ë…¸ë“œ íŠ¹ì„± ì°¨ì›: {node_features.shape}")

        # 5) í•™ìŠµ (ì‹œê°„ìˆœ, ëˆ„ìˆ˜ ë°©ì§€)
        model, train_losses, val_metrics, val_dataset, train_indices, val_indices, adj = source_based_train_gt_tgn_social(
            dataset=dataset,
            node_features=node_features,
            num_nodes=dataset.num_nodes,
            device=device,
            epochs=epochs,
            train_batch_size=train_batch_size,
            val_batch_size=val_batch_size,
            lr=lr
        )

        # 6) ê²€ì¦ ì„¸íŠ¸ í‰ê°€ ë° ì €ì¥ (adjëŠ” train-only)
        results_df = source_based_evaluate_and_save_results(
            model=model,
            dataset_subset=val_dataset,
            node_features=node_features,
            adj=adj,
            past_df=past_df,
            future_df=future_df,
            device=device,
            val_batch_size=val_batch_size,
            out_csv='source_gt_tgn_social_viral_results(re_4000).csv',
            warmup_indices=train_indices  # â† ì—¬ê¸°!
        )

        print("\n=== ì™„ë£Œ ===")
        print(f"ê²€ì¦ ì—£ì§€ ìˆ˜: {len(results_df)}")
        if not results_df.empty:
            print(f"ë°”ì´ëŸ´ ë¼ë²¨ ë¹„ìœ¨: {results_df['actual_viral'].mean()*100:.1f}%")
            print(f"ì˜ˆì¸¡ ë°”ì´ëŸ´ ë¹„ìœ¨: {results_df['predicted_viral'].mean()*100:.1f}%")

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
